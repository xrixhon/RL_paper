\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{numbered}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\citation{cao2020reinforcement}
\citation{sutton2018reinforcement}
\citation{sutton2018reinforcement}
\citation{davidsilver_RL_online}
\citation{haarnoja2018soft}
\citation{haarnoja2018soft}
\newlabel{sec:meth_RL_fundamentals}{{}{2}{Supplementary Note 1 \hspace {2 mm} Reinforcement Learning fundamentals and algorithm}{section*.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces General concept of \acrfull {RL} as the interactions between the agent and its environment. The agent takes some action that has an impact on the environment which feeds back the agent with a reward and the new state. The objective of the agent is to optimise its policy, i.e., the mapping between the state it is at and the action to take, by maximising its cumulative reward.}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:RL_Fundamentals}{{1}{2}{General concept of \acrfull {RL} as the interactions between the agent and its environment. The agent takes some action that has an impact on the environment which feeds back the agent with a reward and the new state. The objective of the agent is to optimise its policy, \ie the mapping between the state it is at and the action to take, by maximising its cumulative reward}{figure.1}{}}
\citation{perera2021applications}
\citation{haarnoja2018soft}
\citation{cao2020reinforcement}
\citation{cao2020reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces General concept of actor-critic-based algorithms. The two \gls *{NN} are trained against each other for the actor to improve the control policy and for the critic to provide a better judgement of the actor's action via the temporal-difference (TD) error. Graph adapted from \cite  {cao2020reinforcement}.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:Actor-critic}{{2}{3}{General concept of actor-critic-based algorithms. The two \gls *{NN} are trained against each other for the actor to improve the control policy and for the critic to provide a better judgement of the actor's action via the temporal-difference (TD) error. Graph adapted from \cite {cao2020reinforcement}}{figure.2}{}}
\citation{haarnoja2017reinforcement}
\citation{ziebart2010modeling}
\citation{haarnoja2017reinforcement}
\citation{haarnoja2017reinforcement}
\citation{raffin2021stable}
\citation{abadi2016tensorflow}
\citation{sutton2018reinforcement}
\citation{haarnoja2018soft}
\newlabel{eq:SAC_objective}{{1}{4}{Supplementary Note 1 \hspace {2 mm} Reinforcement Learning fundamentals and algorithm}{equation.0.1}{}}
\newlabel{sec:comp_PF}{{}{5}{Supplementary Note 2 \hspace {2 mm} Comparison with perfect foresight under uncertainties}{section*.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparison of \ce {CO2} emissions pathways (left) and total transition cost (right) from the perfect foresight optimisation under uncertainties and the \gls *{RL}-based myopic optimisation. Myopic transitions succeed with a more drastic reduction of emissions in the short term and, on average, more favourable economic conditions.}}{5}{figure.3}\protected@file@percent }
\newlabel{fig:Gwp_pathway_total_tran_cost}{{3}{5}{Comparison of \ce {CO2} emissions pathways (left) and total transition cost (right) from the perfect foresight optimisation under uncertainties and the \gls *{RL}-based myopic optimisation. Myopic transitions succeed with a more drastic reduction of emissions in the short term and, on average, more favourable economic conditions}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparison of cumulative OPEX (left), CAPEX (centre) and salvage value (right) in 2050 from the perfect foresight optimisation under uncertainties and the \gls *{RL}-based myopic optimisation.}}{6}{figure.4}\protected@file@percent }
\newlabel{fig:Opex_Capex_Salvage_comp}{{4}{6}{Comparison of cumulative OPEX (left), CAPEX (centre) and salvage value (right) in 2050 from the perfect foresight optimisation under uncertainties and the \gls *{RL}-based myopic optimisation}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison of the primary energy mix in 2050 from the perfect foresight optimisation under uncertainties and the \gls *{RL}-based myopic optimisation. The biggest difference is about e-ammonia to supply \gls *{CCGT}.}}{6}{figure.5}\protected@file@percent }
\newlabel{fig:Mix_2050_comp}{{5}{6}{Comparison of the primary energy mix in 2050 from the perfect foresight optimisation under uncertainties and the \gls *{RL}-based myopic optimisation. The biggest difference is about e-ammonia to supply \gls *{CCGT}}{figure.5}{}}
\citation{bertsimas1997introduction}
\bibdata{references}
\bibcite{cao2020reinforcement}{{1}{2020}{{Cao et~al.}}{{Cao, Hu, Zhao, Zhang, Zhang, Liu, Chen and Blaabjerg}}}
\bibcite{sutton2018reinforcement}{{2}{2018}{{Sutton and Barto}}{{}}}
\bibcite{davidsilver_RL_online}{{3}{2016}{{David Silver}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Binding versus non-binding constraints. In \gls *{LP} where the feasibility domain is non-empty and bounded, the constraints defined a convex feasibility domain in the space of variables (here, x$_1$ and x$_2$). The optimal solution usually locates on a vertex of this domain, i.e., the intersection of several constraints (here, constraints 2 and 3) limiting the solution. These constraints are considered binding, i.e., having a limiting impact on the optimal solution.}}{7}{figure.6}\protected@file@percent }
\newlabel{fig:Binding_constr}{{6}{7}{Binding versus non-binding constraints. In \gls *{LP} where the feasibility domain is non-empty and bounded, the constraints defined a convex feasibility domain in the space of variables (here, x$_1$ and x$_2$). The optimal solution usually locates on a vertex of this domain, \ie the intersection of several constraints (here, constraints 2 and 3) limiting the solution. These constraints are considered binding, \ie having a limiting impact on the optimal solution}{figure.6}{}}
\newlabel{sec:binding}{{}{7}{Supplementary Note 3 \hspace {2 mm} To bind or not to bind, that is the question}{section*.3}{}}
\bibcite{haarnoja2018soft}{{4}{2018}{{Haarnoja et~al.}}{{Haarnoja, Zhou, Abbeel and Levine}}}
\bibcite{perera2021applications}{{5}{2021}{{Perera and Kamalaruban}}{{}}}
\bibcite{haarnoja2017reinforcement}{{6}{2017}{{Haarnoja et~al.}}{{Haarnoja, Tang, Abbeel and Levine}}}
\bibcite{ziebart2010modeling}{{7}{2010}{{Ziebart}}{{}}}
\bibcite{raffin2021stable}{{8}{2021}{{Raffin et~al.}}{{Raffin, Hill, Gleave, Kanervisto, Ernestus and Dormann}}}
\bibcite{abadi2016tensorflow}{{9}{2016}{{Abadi et~al.}}{{Abadi, Agarwal, Barham, Brevdo, Chen, Citro, Corrado, Davis, Dean, Devin et~al.}}}
\bibcite{bertsimas1997introduction}{{10}{1997}{{Bertsimas and Tsitsiklis}}{{}}}
\gdef \@abspage@last{8}
